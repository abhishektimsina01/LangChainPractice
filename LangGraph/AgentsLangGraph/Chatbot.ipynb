{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7a1907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nitro\\Desktop\\Desk\\CampusX\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c5b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages : Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cde48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=os.getenv(\"model\"),\n",
    "    api_key=os.getenv(\"api_key\")\n",
    ")\n",
    "def chatModel(state : ChatState):\n",
    "    message = state[\"messages\"]\n",
    "    response = llm.invoke(message)\n",
    "    return {'messages' : [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fdeb7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001C8194BB380>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = MemorySaver()\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "graph.add_node(\"ChatModel\", chatModel)\n",
    "graph.add_edge(START, \"ChatModel\")\n",
    "graph.add_edge(\"ChatModel\", END)\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer)\n",
    "workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e251a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is pytorch?', additional_kwargs={}, response_metadata={}, id='a57f1d5e-2bdb-408f-849c-30ae488d8c20'),\n",
       "  AIMessage(content='PyTorch is an open‚Äësource machine‚Äëlearning library developed by Meta (formerly Facebook) that provides tools for building and training deep neural networks. It combines:\\n\\n* **Tensor computation** ‚Äì a flexible, GPU‚Äëaccelerated array (tensor) library with automatic differentiation (the ‚Äúautograd‚Äù system) that tracks operations to compute gradients for back‚Äëpropagation.\\n* **Dynamic computation graphs** ‚Äì unlike static‚Äëgraph frameworks, PyTorch builds the graph on the fly as you execute code, making debugging and model development more intuitive.\\n* **High‚Äëlevel APIs** ‚Äì modules such as `torch.nn` for defining layers, `torch.optim` for optimization algorithms, and utilities for data loading (`torch.utils.data`) and model serialization.\\n* **Ecosystem** ‚Äì extensions like TorchVision (vision), TorchText (NLP), TorchAudio (audio), and libraries such as PyTorch Lightning, Hugging Face Transformers, and fastai that simplify research and production pipelines.\\n\\nOverall, PyTorch is widely used in research and industry for tasks ranging from computer vision and natural language processing to reinforcement learning and scientific computing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 561, 'prompt_tokens': 445, 'total_tokens': 1006, 'completion_time': 1.487191, 'completion_tokens_details': None, 'prompt_time': 0.05359, 'prompt_tokens_details': None, 'queue_time': 0.529529, 'total_time': 1.540781}, 'model_name': 'groq/compound-mini', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b93ed-ea19-7e90-ba15-322ab67f2b3f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 445, 'output_tokens': 561, 'total_tokens': 1006})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable' : {'thread_id' : 1}}\n",
    "intial = {'messages' : [(HumanMessage(content='What is pytorch?'))]}\n",
    "workflow.invoke(intial, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8adc1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de9086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  tell me more about it\n",
      "AI:  ### PyTorch ‚Äì A Deeper Look  \n",
      "\n",
      "| Aspect | What It Is | Why It Matters |\n",
      "|--------|------------|----------------|\n",
      "| **Origin & Governance** | Launched in 2016 by Facebook AI Research (FAIR). Now an open‚Äësource project under the **PyTorch Foundation** (Linux Foundation) with contributions from academia, industry, and the community. | Guarantees long‚Äëterm support, transparent governance, and a vibrant ecosystem. |\n",
      "| **Core Data Structure ‚Äì‚ÄØTensor** | Multi‚Äëdimensional array (like NumPy) that can live on CPU **or** GPU (CUDA, AMD ROCm, Apple‚ÄØMetal). Supports sparse tensors, complex numbers, and quantized types. | Enables high‚Äëperformance numerical computing and seamless GPU acceleration. |\n",
      "| **Autograd (Automatic Differentiation)** | Records every operation on tensors in a **dynamic computation graph**. When `loss.backward()` is called, it traverses the graph backward to compute gradients automatically. | Eliminates manual derivative coding, making research iteration fast and debugging easy (the graph is built at runtime, so you can use Python control flow). |\n",
      "| **nn.Module & torch.nn** | Base class for all neural‚Äënetwork components. Provides: <br>‚Ä¢ Layer building blocks (`Linear`, `Conv2d`, `LSTM`, ‚Ä¶) <br>‚Ä¢ Container modules (`Sequential`, `ModuleList`) <br>‚Ä¢ Parameter handling (`self.parameters()`) | Gives a clean, object‚Äëoriented way to define models, reuse components, and move entire networks between devices (`model.to(device)`). |\n",
      "| **Optimizers (torch.optim)** | Ready‚Äëmade algorithms: SGD, Adam, RMSprop, AdamW, LAMB, etc. Each optimizer updates the parameters using the gradients computed by autograd. | Lets you experiment with different training dynamics without writing update rules yourself. |\n",
      "| **Loss Functions (torch.nn.functional / torch.nn)** | Common losses (CrossEntropy, MSE, NLL, BCEWithLogits, CTCLoss) and functional APIs for custom losses. | Standardized, numerically stable implementations that integrate with autograd. |\n",
      "| **Data Pipeline (torch.utils.data)** | `Dataset` abstraction for arbitrary data sources, `DataLoader` for batching, shuffling, multi‚Äëprocess loading, and automatic collation. | Handles large‚Äëscale data efficiently and works out‚Äëof‚Äëthe‚Äëbox with GPUs. |\n",
      "| **TorchScript & JIT Compilation** | Two ways to ‚Äúfreeze‚Äù a model: <br>‚Ä¢ **Tracing** (`torch.jit.trace`) ‚Äì records tensor operations on example inputs.<br>‚Ä¢ **Scripting** (`torch.jit.script`) ‚Äì compiles Python code with control flow. <br>Result is a portable, optimizable graph that can run in C++ without Python. | Enables production deployment, mobile inference, and performance gains (fusion, constant folding). |\n",
      "| **Distributed Training** | ‚Ä¢ **torch.distributed** ‚Äì low‚Äëlevel primitives (process groups, collective ops). <br>‚Ä¢ **torch.nn.parallel.DistributedDataParallel (DDP)** ‚Äì recommended multi‚ÄëGPU/multi‚Äënode wrapper. <br>‚Ä¢ **torchrun** (formerly `torch.distributed.launch`). | Scales training from a single GPU to hundreds of GPUs across clusters with near‚Äëlinear speed‚Äëup. |\n",
      "| **Mixed‚ÄëPrecision & Quantization** | ‚Ä¢ **AMP (Automatic Mixed Precision)** ‚Äì `torch.cuda.amp` automatically casts ops to FP16 where safe. <br>‚Ä¢ **Quantization** ‚Äì post‚Äëtraining static, dynamic, and quantization‚Äëaware training pipelines. | Reduces memory footprint and speeds up inference on modern hardware (NVIDIA Tensor Cores, ARM CPUs, etc.). |\n",
      "| **Ecosystem & Extensions** | **Vision** ‚Äì TorchVision (datasets, transforms, pretrained models). <br>**NLP** ‚Äì TorchText, Hugging Face ü§ó Transformers (built on PyTorch). <br>**Audio** ‚Äì TorchAudio. <br>**Reinforcement Learning** ‚Äì TorchRL. <br>**Higher‚Äëlevel frameworks** ‚Äì PyTorch Lightning, fastai, Catalyst, Ignite. | Allows you to plug‚Äëand‚Äëplay domain‚Äëspecific tools, accelerate research, and adopt best‚Äëpractice training loops. |\n",
      "| **Deployment Options** | ‚Ä¢ **TorchServe** ‚Äì model serving with REST/gRPC, auto‚Äëscaling, logging. <br>‚Ä¢ **ONNX Export** ‚Äì `torch.onnx.export` ‚Üí run on any ONNX runtime (TensorRT, OpenVINO, etc.). <br>‚Ä¢ **Mobile** ‚Äì `torchscript` + `pytorch-mobile` for iOS/Android. <br>‚Ä¢ **Edge** ‚Äì integration with TVM, TensorRT, or custom C++ inference engines. | Gives flexibility from cloud servers to edge devices, without rewriting the model. |\n",
      "| **Interoperability** | Works with NumPy (`tensor.numpy()`), Pandas, SciPy, and other Python scientific libraries. Supports **CUDA**, **ROCm**, **Apple Metal**, **DirectML**, and **CPU** back‚Äëends. | You can embed PyTorch in existing Python pipelines and run on virtually any hardware. |\n",
      "| **Community & Resources** | ‚Ä¢ Over 70‚ÄØk GitHub stars, active forums, Slack, Discord. <br>‚Ä¢ Official tutorials, documentation, and a yearly **PyTorch Conference**. <br>‚Ä¢ Model Zoo (torch.hub) and **Hugging Face Hub** with thousands of pretrained checkpoints. | Easy to find help, tutorials, and ready‚Äëmade models for almost any task. |\n",
      "\n",
      "---\n",
      "\n",
      "## Typical Workflow (Illustrative Code)\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "from torch.utils.data import DataLoader, random_split\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "# 1Ô∏è‚É£ Data\n",
      "transform = transforms.Compose([\n",
      "    transforms.ToTensor(),\n",
      "    transforms.Normalize((0.1307,), (0.3081,))\n",
      "])\n",
      "full_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
      "train_set, val_set = random_split(full_dataset, [55000, 5000])\n",
      "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
      "\n",
      "# 2Ô∏è‚É£ Model\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.conv = nn.Conv2d(1, 32, 3, 1)\n",
      "        self.fc   = nn.Linear(5408, 10)   # after flattening\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = torch.relu(self.conv(x))\n",
      "        x = torch.flatten(x, 1)\n",
      "        return self.fc(x)\n",
      "\n",
      "model = Net().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "# 3Ô∏è‚É£ Loss + Optimizer\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
      "\n",
      "# 4Ô∏è‚É£ Training loop (with AMP)\n",
      "scaler = torch.cuda.amp.GradScaler()\n",
      "for epoch in range(5):\n",
      "    model.train()\n",
      "    for imgs, targets in train_loader:\n",
      "        imgs, targets = imgs.to(model.device), targets.to(model.device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "        with torch.cuda.amp.autocast():\n",
      "            outputs = model(imgs)\n",
      "            loss = criterion(outputs, targets)\n",
      "        scaler.scale(loss).backward()\n",
      "        scaler.step(optimizer)\n",
      "        scaler.update()\n",
      "    print(f'Epoch {epoch+1} finished')\n",
      "```\n",
      "\n",
      "*The snippet shows the typical pieces: data loading, a `nn.Module`, loss/optimizer, mixed‚Äëprecision training, and device‚Äëagnostic code.*\n",
      "\n",
      "---\n",
      "\n",
      "## How PyTorch Differs from TensorFlow (high‚Äëlevel)\n",
      "\n",
      "| Feature | PyTorch | TensorFlow |\n",
      "|---------|---------|------------|\n",
      "| **Computation graph** | Dynamic (eager) by default ‚Üí easier debugging. | Static graph (`tf.function`) by default, but eager execution also available. |\n",
      "| **Pythonic API** | Very close to native Python/NumPy; you write regular Python control flow. | Historically required `tf.Graph` constructs; now more Pythonic but still a bit more verbose. |\n",
      "| **Model serialization** | `torch.save` (pickle) for Python objects; `torchscript` for language‚Äëagnostic deployment. | `SavedModel` format (protocol buffers). |\n",
      "| **Distributed training** | `torch.distributed` + DDP is straightforward; works well with SLURM, Kubernetes. | `tf.distribute` strategies (MirroredStrategy, MultiWorkerMirroredStrategy). |\n",
      "| **Ecosystem focus** | Strong in research, especially vision/NLP; many community‚Äëdriven libraries. | Strong in production pipelines (TF Serving, TensorFlow Lite, TensorFlow.js). |\n",
      "| **Community & adoption** | Rapidly growing; many top‚Äëconference papers use PyTorch. | Still widely used, especially in Google‚Äëcentric stacks. |\n",
      "\n",
      "Both frameworks can accomplish the same tasks; the choice often comes down to team familiarity, existing tooling, and deployment targets.\n",
      "\n",
      "---\n",
      "\n",
      "## When to Choose PyTorch\n",
      "\n",
      "| Scenario | Reason |\n",
      "|----------|--------|\n",
      "| **Rapid prototyping / research** | Dynamic graph + Pythonic syntax ‚Üí iterate quickly. |\n",
      "| **Complex control flow** (e.g., variable‚Äëlength loops, conditionals) | Autograd works naturally with Python `if/for/while`. |\n",
      "| **Vision/NLP projects** | Rich libraries (TorchVision, ü§ó Transformers) and many pretrained checkpoints. |\n",
      "| **Mixed‚Äëprecision or quantization** | Built‚Äëin `torch.cuda.amp` and quantization APIs are simple to enable. |\n",
      "| **Large‚Äëscale distributed training** | DDP + NCCL integration gives near‚Äëlinear scaling. |\n",
      "| **Edge or mobile deployment** | TorchScript + PyTorch Mobile provides a single‚Äëcode‚Äëbase path. |\n",
      "\n",
      "---\n",
      "\n",
      "## Getting Started Resources\n",
      "\n",
      "| Resource | Link |\n",
      "|----------|------|\n",
      "| Official Docs | https://pytorch.org/docs |\n",
      "| Beginner Tutorial (MNIST) | https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html |\n",
      "| TorchVision Models | https://pytorch.org/vision/stable/models |\n",
      "| Hugging Face Transformers (PyTorch) | https://huggingface.co/docs/transformers/index |\n",
      "| PyTorch Lightning (high‚Äëlevel training loop) | https://pytorch-lightning.readthedocs.io |\n",
      "| Distributed Training Guide | https://pytorch.org/tutorials/beginner/ddp_series.html |\n",
      "| TorchServe Quickstart | https://pytorch.org/serve/ |\n",
      "\n",
      "---\n",
      "\n",
      "### TL;DR\n",
      "\n",
      "- **PyTorch** is an open‚Äësource, Python‚Äëfirst deep‚Äëlearning library built around tensors, automatic differentiation, and a dynamic computation graph.  \n",
      "- It provides a clean `nn.Module` API, powerful optimizers, data utilities, and extensive tooling for scaling, mixed‚Äëprecision, quantization, and deployment.  \n",
      "- Its ecosystem (TorchVision, TorchText, Hugging‚ÄØFace, Lightning, etc.) makes it a go‚Äëto choice for research and production across vision, NLP, audio, reinforcement learning, and more.  \n",
      "\n",
      "Feel free to ask if you‚Äôd like a walkthrough of a specific domain (e.g., building a transformer, training on multiple GPUs, exporting to ONNX, etc.).\n"
     ]
    }
   ],
   "source": [
    "thread_id1 = 1\n",
    "thread_id2 = 2\n",
    "while True:\n",
    "    query = input(\"type here\")\n",
    "\n",
    "    if query.strip().lower() in [\"exit\", \"bye\", \"quit\"]:\n",
    "        break\n",
    "    else:\n",
    "        config = {'configurable' : {'thread_id' : thread_id1}}\n",
    "        print(\"User: \",query)\n",
    "        print(\"AI: \",workflow.invoke({\"messages\" : [HumanMessage(content=query)]}, config=config)['messages'][-1].content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55cdfa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='What is pytorch?', additional_kwargs={}, response_metadata={}, id='a57f1d5e-2bdb-408f-849c-30ae488d8c20'), AIMessage(content='PyTorch is an open‚Äësource machine‚Äëlearning library developed by Meta (formerly Facebook) that provides tools for building and training deep neural networks. It combines:\\n\\n* **Tensor computation** ‚Äì a flexible, GPU‚Äëaccelerated array (tensor) library with automatic differentiation (the ‚Äúautograd‚Äù system) that tracks operations to compute gradients for back‚Äëpropagation.\\n* **Dynamic computation graphs** ‚Äì unlike static‚Äëgraph frameworks, PyTorch builds the graph on the fly as you execute code, making debugging and model development more intuitive.\\n* **High‚Äëlevel APIs** ‚Äì modules such as `torch.nn` for defining layers, `torch.optim` for optimization algorithms, and utilities for data loading (`torch.utils.data`) and model serialization.\\n* **Ecosystem** ‚Äì extensions like TorchVision (vision), TorchText (NLP), TorchAudio (audio), and libraries such as PyTorch Lightning, Hugging Face Transformers, and fastai that simplify research and production pipelines.\\n\\nOverall, PyTorch is widely used in research and industry for tasks ranging from computer vision and natural language processing to reinforcement learning and scientific computing.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 561, 'prompt_tokens': 445, 'total_tokens': 1006, 'completion_time': 1.487191, 'completion_tokens_details': None, 'prompt_time': 0.05359, 'prompt_tokens_details': None, 'queue_time': 0.529529, 'total_time': 1.540781}, 'model_name': 'groq/compound-mini', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b93ed-ea19-7e90-ba15-322ab67f2b3f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 445, 'output_tokens': 561, 'total_tokens': 1006}), HumanMessage(content='tell me more about it', additional_kwargs={}, response_metadata={}, id='40cadc50-8ede-4b0d-9e63-23cdb20290b9'), AIMessage(content=\"### PyTorch ‚Äì A Deeper Look  \\n\\n| Aspect | What It Is | Why It Matters |\\n|--------|------------|----------------|\\n| **Origin & Governance** | Launched in 2016 by Facebook AI Research (FAIR). Now an open‚Äësource project under the **PyTorch Foundation** (Linux Foundation) with contributions from academia, industry, and the community. | Guarantees long‚Äëterm support, transparent governance, and a vibrant ecosystem. |\\n| **Core Data Structure ‚Äì\\u202fTensor** | Multi‚Äëdimensional array (like NumPy) that can live on CPU **or** GPU (CUDA, AMD ROCm, Apple\\u202fMetal). Supports sparse tensors, complex numbers, and quantized types. | Enables high‚Äëperformance numerical computing and seamless GPU acceleration. |\\n| **Autograd (Automatic Differentiation)** | Records every operation on tensors in a **dynamic computation graph**. When `loss.backward()` is called, it traverses the graph backward to compute gradients automatically. | Eliminates manual derivative coding, making research iteration fast and debugging easy (the graph is built at runtime, so you can use Python control flow). |\\n| **nn.Module & torch.nn** | Base class for all neural‚Äënetwork components. Provides: <br>‚Ä¢ Layer building blocks (`Linear`, `Conv2d`, `LSTM`, ‚Ä¶) <br>‚Ä¢ Container modules (`Sequential`, `ModuleList`) <br>‚Ä¢ Parameter handling (`self.parameters()`) | Gives a clean, object‚Äëoriented way to define models, reuse components, and move entire networks between devices (`model.to(device)`). |\\n| **Optimizers (torch.optim)** | Ready‚Äëmade algorithms: SGD, Adam, RMSprop, AdamW, LAMB, etc. Each optimizer updates the parameters using the gradients computed by autograd. | Lets you experiment with different training dynamics without writing update rules yourself. |\\n| **Loss Functions (torch.nn.functional / torch.nn)** | Common losses (CrossEntropy, MSE, NLL, BCEWithLogits, CTCLoss) and functional APIs for custom losses. | Standardized, numerically stable implementations that integrate with autograd. |\\n| **Data Pipeline (torch.utils.data)** | `Dataset` abstraction for arbitrary data sources, `DataLoader` for batching, shuffling, multi‚Äëprocess loading, and automatic collation. | Handles large‚Äëscale data efficiently and works out‚Äëof‚Äëthe‚Äëbox with GPUs. |\\n| **TorchScript & JIT Compilation** | Two ways to ‚Äúfreeze‚Äù a model: <br>‚Ä¢ **Tracing** (`torch.jit.trace`) ‚Äì records tensor operations on example inputs.<br>‚Ä¢ **Scripting** (`torch.jit.script`) ‚Äì compiles Python code with control flow. <br>Result is a portable, optimizable graph that can run in C++ without Python. | Enables production deployment, mobile inference, and performance gains (fusion, constant folding). |\\n| **Distributed Training** | ‚Ä¢ **torch.distributed** ‚Äì low‚Äëlevel primitives (process groups, collective ops). <br>‚Ä¢ **torch.nn.parallel.DistributedDataParallel (DDP)** ‚Äì recommended multi‚ÄëGPU/multi‚Äënode wrapper. <br>‚Ä¢ **torchrun** (formerly `torch.distributed.launch`). | Scales training from a single GPU to hundreds of GPUs across clusters with near‚Äëlinear speed‚Äëup. |\\n| **Mixed‚ÄëPrecision & Quantization** | ‚Ä¢ **AMP (Automatic Mixed Precision)** ‚Äì `torch.cuda.amp` automatically casts ops to FP16 where safe. <br>‚Ä¢ **Quantization** ‚Äì post‚Äëtraining static, dynamic, and quantization‚Äëaware training pipelines. | Reduces memory footprint and speeds up inference on modern hardware (NVIDIA Tensor Cores, ARM CPUs, etc.). |\\n| **Ecosystem & Extensions** | **Vision** ‚Äì TorchVision (datasets, transforms, pretrained models). <br>**NLP** ‚Äì TorchText, Hugging Face ü§ó Transformers (built on PyTorch). <br>**Audio** ‚Äì TorchAudio. <br>**Reinforcement Learning** ‚Äì TorchRL. <br>**Higher‚Äëlevel frameworks** ‚Äì PyTorch Lightning, fastai, Catalyst, Ignite. | Allows you to plug‚Äëand‚Äëplay domain‚Äëspecific tools, accelerate research, and adopt best‚Äëpractice training loops. |\\n| **Deployment Options** | ‚Ä¢ **TorchServe** ‚Äì model serving with REST/gRPC, auto‚Äëscaling, logging. <br>‚Ä¢ **ONNX Export** ‚Äì `torch.onnx.export` ‚Üí run on any ONNX runtime (TensorRT, OpenVINO, etc.). <br>‚Ä¢ **Mobile** ‚Äì `torchscript` + `pytorch-mobile` for iOS/Android. <br>‚Ä¢ **Edge** ‚Äì integration with TVM, TensorRT, or custom C++ inference engines. | Gives flexibility from cloud servers to edge devices, without rewriting the model. |\\n| **Interoperability** | Works with NumPy (`tensor.numpy()`), Pandas, SciPy, and other Python scientific libraries. Supports **CUDA**, **ROCm**, **Apple Metal**, **DirectML**, and **CPU** back‚Äëends. | You can embed PyTorch in existing Python pipelines and run on virtually any hardware. |\\n| **Community & Resources** | ‚Ä¢ Over 70\\u202fk GitHub stars, active forums, Slack, Discord. <br>‚Ä¢ Official tutorials, documentation, and a yearly **PyTorch Conference**. <br>‚Ä¢ Model Zoo (torch.hub) and **Hugging Face Hub** with thousands of pretrained checkpoints. | Easy to find help, tutorials, and ready‚Äëmade models for almost any task. |\\n\\n---\\n\\n## Typical Workflow (Illustrative Code)\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nfrom torch.utils.data import DataLoader, random_split\\nfrom torchvision import datasets, transforms\\n\\n# 1Ô∏è‚É£ Data\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.1307,), (0.3081,))\\n])\\nfull_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\\ntrain_set, val_set = random_split(full_dataset, [55000, 5000])\\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\\n\\n# 2Ô∏è‚É£ Model\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.conv = nn.Conv2d(1, 32, 3, 1)\\n        self.fc   = nn.Linear(5408, 10)   # after flattening\\n\\n    def forward(self, x):\\n        x = torch.relu(self.conv(x))\\n        x = torch.flatten(x, 1)\\n        return self.fc(x)\\n\\nmodel = Net().to('cuda' if torch.cuda.is_available() else 'cpu')\\n\\n# 3Ô∏è‚É£ Loss + Optimizer\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)\\n\\n# 4Ô∏è‚É£ Training loop (with AMP)\\nscaler = torch.cuda.amp.GradScaler()\\nfor epoch in range(5):\\n    model.train()\\n    for imgs, targets in train_loader:\\n        imgs, targets = imgs.to(model.device), targets.to(model.device)\\n\\n        optimizer.zero_grad()\\n        with torch.cuda.amp.autocast():\\n            outputs = model(imgs)\\n            loss = criterion(outputs, targets)\\n        scaler.scale(loss).backward()\\n        scaler.step(optimizer)\\n        scaler.update()\\n    print(f'Epoch {epoch+1} finished')\\n```\\n\\n*The snippet shows the typical pieces: data loading, a `nn.Module`, loss/optimizer, mixed‚Äëprecision training, and device‚Äëagnostic code.*\\n\\n---\\n\\n## How PyTorch Differs from TensorFlow (high‚Äëlevel)\\n\\n| Feature | PyTorch | TensorFlow |\\n|---------|---------|------------|\\n| **Computation graph** | Dynamic (eager) by default ‚Üí easier debugging. | Static graph (`tf.function`) by default, but eager execution also available. |\\n| **Pythonic API** | Very close to native Python/NumPy; you write regular Python control flow. | Historically required `tf.Graph` constructs; now more Pythonic but still a bit more verbose. |\\n| **Model serialization** | `torch.save` (pickle) for Python objects; `torchscript` for language‚Äëagnostic deployment. | `SavedModel` format (protocol buffers). |\\n| **Distributed training** | `torch.distributed` + DDP is straightforward; works well with SLURM, Kubernetes. | `tf.distribute` strategies (MirroredStrategy, MultiWorkerMirroredStrategy). |\\n| **Ecosystem focus** | Strong in research, especially vision/NLP; many community‚Äëdriven libraries. | Strong in production pipelines (TF Serving, TensorFlow Lite, TensorFlow.js). |\\n| **Community & adoption** | Rapidly growing; many top‚Äëconference papers use PyTorch. | Still widely used, especially in Google‚Äëcentric stacks. |\\n\\nBoth frameworks can accomplish the same tasks; the choice often comes down to team familiarity, existing tooling, and deployment targets.\\n\\n---\\n\\n## When to Choose PyTorch\\n\\n| Scenario | Reason |\\n|----------|--------|\\n| **Rapid prototyping / research** | Dynamic graph + Pythonic syntax ‚Üí iterate quickly. |\\n| **Complex control flow** (e.g., variable‚Äëlength loops, conditionals) | Autograd works naturally with Python `if/for/while`. |\\n| **Vision/NLP projects** | Rich libraries (TorchVision, ü§ó Transformers) and many pretrained checkpoints. |\\n| **Mixed‚Äëprecision or quantization** | Built‚Äëin `torch.cuda.amp` and quantization APIs are simple to enable. |\\n| **Large‚Äëscale distributed training** | DDP + NCCL integration gives near‚Äëlinear scaling. |\\n| **Edge or mobile deployment** | TorchScript + PyTorch Mobile provides a single‚Äëcode‚Äëbase path. |\\n\\n---\\n\\n## Getting Started Resources\\n\\n| Resource | Link |\\n|----------|------|\\n| Official Docs | https://pytorch.org/docs |\\n| Beginner Tutorial (MNIST) | https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html |\\n| TorchVision Models | https://pytorch.org/vision/stable/models |\\n| Hugging Face Transformers (PyTorch) | https://huggingface.co/docs/transformers/index |\\n| PyTorch Lightning (high‚Äëlevel training loop) | https://pytorch-lightning.readthedocs.io |\\n| Distributed Training Guide | https://pytorch.org/tutorials/beginner/ddp_series.html |\\n| TorchServe Quickstart | https://pytorch.org/serve/ |\\n\\n---\\n\\n### TL;DR\\n\\n- **PyTorch** is an open‚Äësource, Python‚Äëfirst deep‚Äëlearning library built around tensors, automatic differentiation, and a dynamic computation graph.  \\n- It provides a clean `nn.Module` API, powerful optimizers, data utilities, and extensive tooling for scaling, mixed‚Äëprecision, quantization, and deployment.  \\n- Its ecosystem (TorchVision, TorchText, Hugging\\u202fFace, Lightning, etc.) makes it a go‚Äëto choice for research and production across vision, NLP, audio, reinforcement learning, and more.  \\n\\nFeel free to ask if you‚Äôd like a walkthrough of a specific domain (e.g., building a transformer, training on multiple GPUs, exporting to ONNX, etc.).\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 2445, 'prompt_tokens': 927, 'total_tokens': 3372, 'completion_time': 5.166156, 'completion_tokens_details': None, 'prompt_time': 0.044259, 'prompt_tokens_details': None, 'queue_time': 0.110234, 'total_time': 5.210415}, 'model_name': 'groq/compound-mini', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b93ee-3d27-7320-a491-0eb9f28f2553-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 927, 'output_tokens': 2445, 'total_tokens': 3372})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0eb14a-1c96-6096-8004-793df57977a9'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2026-01-06T15:30:29.468755+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0eb149-db5f-630d-8003-993835b27ed3'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
